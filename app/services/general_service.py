import re
import json
from app.utils.ollama_runner import ollama_generate
from fastapi import HTTPException
import logging

logging.basicConfig(level=logging.DEBUG)  # Configure logging level

def get_general_response(prompt: str) -> dict:
    try:
        logging.debug("DEBUG: Sending prompt to Ollama...")
        # [ğŸ‡¬ğŸ‡§ DEBUG: Sending prompt to Ollama...] | [ğŸ‡ªğŸ‡¸ DEPURACIÃ“N: Enviando prompt a Ollama...] | [ğŸ‡µğŸ‡¹ DEPURAÃ‡ÃƒO: Enviando prompt para Ollama...] | [ğŸ‡¯ğŸ‡µ ãƒ‡ãƒãƒƒã‚°: Ollama ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡ä¸­...] | [ğŸ‡·ğŸ‡º ĞĞ¢Ğ›ĞĞ”ĞšĞ: ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğ² Ollama...] | [ğŸ‡¸ğŸ‡¦ ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡: Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø¥Ù„Ù‰ Ollama...]
        response = ollama_generate("llama3.2", prompt)  # Call to Ollama
        # [ğŸ‡¬ğŸ‡§ Call to Ollama] | [ğŸ‡ªğŸ‡¸ Llamada a Ollama] | [ğŸ‡µğŸ‡¹ Chamada para Ollama] | [ğŸ‡¯ğŸ‡µ Ollama ã¸ã®å‘¼ã³å‡ºã—] | [ğŸ‡·ğŸ‡º Ğ’Ñ‹Ğ·Ğ¾Ğ² Ollama] | [ğŸ‡¸ğŸ‡¦ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ollama]
        logging.debug("DEBUG: Raw response from Ollama: %s", response)
        # [ğŸ‡¬ğŸ‡§ DEBUG: Raw response from Ollama: %s] | [ğŸ‡ªğŸ‡¸ DEPURACIÃ“N: Respuesta bruta de Ollama: %s] | [ğŸ‡µğŸ‡¹ DEPURAÃ‡ÃƒO: Resposta bruta de Ollama: %s] | [ğŸ‡¯ğŸ‡µ ãƒ‡ãƒãƒƒã‚°: Ollama ã‹ã‚‰ã®ç”Ÿã®å¿œç­”: %s] | [ğŸ‡·ğŸ‡º ĞĞ¢Ğ›ĞĞ”ĞšĞ: Ğ¡Ñ‹Ñ€Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ Ollama: %s] | [ğŸ‡¸ğŸ‡¦ ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡: Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ù…Ù† Ollama: %s]
    except Exception as e:
        logging.error("Error during call to Ollama: %s", str(e))
        # [ğŸ‡¬ğŸ‡§ Error during call to Ollama: %s] | [ğŸ‡ªğŸ‡¸ Error durante la llamada a Ollama: %s] | [ğŸ‡µğŸ‡¹ Erro durante a chamada para Ollama: %s] | [ğŸ‡¯ğŸ‡µ Ollama ã¸ã®å‘¼ã³å‡ºã—ä¸­ã®ã‚¨ãƒ©ãƒ¼: %s] | [ğŸ‡·ğŸ‡º ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğµ Ollama: %s] | [ğŸ‡¸ğŸ‡¦ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ollama: %s]
        raise HTTPException(status_code=500, detail="Internal error during call to Ollama.")
        # [ğŸ‡¬ğŸ‡§ Internal error during call to Ollama] | [ğŸ‡ªğŸ‡¸ Error interno durante la llamada a Ollama] | [ğŸ‡µğŸ‡¹ Erro interno durante a chamada para Ollama] | [ğŸ‡¯ğŸ‡µ Ollama ã¸ã®å‘¼ã³å‡ºã—ä¸­ã®å†…éƒ¨ã‚¨ãƒ©ãƒ¼] | [ğŸ‡·ğŸ‡º Ğ’Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ÑÑ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğµ Ollama] | [ğŸ‡¸ğŸ‡¦ Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ollama]

    # Check if the response contains an error
    # [ğŸ‡¬ğŸ‡§ Check if the response contains an error] | [ğŸ‡ªğŸ‡¸ Verificar si la respuesta contiene un error] | [ğŸ‡µğŸ‡¹ Verificar se a resposta contÃ©m um erro] | [ğŸ‡¯ğŸ‡µ å¿œç­”ã«ã‚¨ãƒ©ãƒ¼ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª] | [ğŸ‡·ğŸ‡º ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ»Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ] | [ğŸ‡¸ğŸ‡¦ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø®Ø·Ø£]
    if "error" in response:
        logging.error("Error returned by Ollama: %s", response["error"])
        # [ğŸ‡¬ğŸ‡§ Error returned by Ollama: %s] | [ğŸ‡ªğŸ‡¸ Error devuelto por Ollama: %s] | [ğŸ‡µğŸ‡¹ Erro retornado por Ollama: %s] | [ğŸ‡¯ğŸ‡µ Ollama ã‹ã‚‰è¿”ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼: %s] | [ğŸ‡·ğŸ‡º ĞÑˆĞ¸Ğ±ĞºĞ°, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ½Ğ°Ñ Ollama: %s] | [ğŸ‡¸ğŸ‡¦ Ø®Ø·Ø£ ØªÙ… Ø¥Ø±Ø¬Ø§Ø¹Ù‡ Ø¨ÙˆØ§Ø³Ø·Ø© Ollama: %s]
        raise HTTPException(status_code=404, detail="Ollama model not found or unreachable.")
        # [ğŸ‡¬ğŸ‡§ Ollama model not found or unreachable] | [ğŸ‡ªğŸ‡¸ Modelo de Ollama no encontrado o inalcanzable] | [ğŸ‡µğŸ‡¹ Modelo Ollama nÃ£o encontrado ou inacessÃ­vel] | [ğŸ‡¯ğŸ‡µ Ollama ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€åˆ°é”ä¸èƒ½ã§ã™] | [ğŸ‡·ğŸ‡º ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ollama Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° Ğ¸Ğ»Ğ¸ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ°] | [ğŸ‡¸ğŸ‡¦ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Ollama Ø£Ùˆ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„ÙŠÙ‡]

    # Return the cleaned response
    # [ğŸ‡¬ğŸ‡§ Return the cleaned response] | [ğŸ‡ªğŸ‡¸ Devolver la respuesta limpia] | [ğŸ‡µğŸ‡¹ Retornar a resposta limpa] | [ğŸ‡¯ğŸ‡µ ã‚¯ãƒªãƒ¼ãƒ³ãªå¿œç­”ã‚’è¿”ã™] | [ğŸ‡·ğŸ‡º Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚] | [ğŸ‡¸ğŸ‡¦ Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù…Ù†Ø¸ÙØ©]
    return response
